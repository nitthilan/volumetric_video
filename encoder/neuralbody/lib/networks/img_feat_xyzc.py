import torch.nn as nn
import spconv.pytorch as spconv
import torch.nn.functional as F
import torch
from lib.config import cfg
from . import embedder

# List of things to change
#   - just using mean, var and both
#   - with and without 3D conv
#   - how to merge the data generated by different GPUs
#   - Modify the 3D conv num channels to match the input features

class Network(nn.Module):
    def __init__(self):
        super(Network, self).__init__()

        # self.c = nn.Embedding(6890, 16)
        self.xyzc_net = SparseConvNet()
        # self.xyzc_net = SimSparseConvNet()

        # self.latent = nn.Embedding(cfg.num_train_frame, 128)

        self.actvn = nn.ReLU()

        self.fc_0 = nn.Conv1d(640, 512, 1)
        self.fc_1 = nn.Conv1d(512, 256, 1)
        self.fc_2 = nn.Conv1d(256, 256, 1)
        self.alpha_fc = nn.Conv1d(256, 1, 1)

        self.feature_fc = nn.Conv1d(256, 256, 1)
        # self.latent_fc = nn.Conv1d(256, 256, 1)
        # self.view_fc = nn.Conv1d(346, 128, 1)
        self.view_fc = nn.Conv1d(283, 128, 1)
        self.rgb_fc = nn.Conv1d(128, 3, 1)

    def set_vol_feat(self, vol_feat):
        # ('mean_feat', mean_feat),
        #     ('var_sqr_feat', var_sqr_feat),
        #     ('out_sh', self.vox_steps),
        #     ('batch_size', torch.sum(vox_idx)),

        # print("Input ", vol_feat['batch_size'], cfg.local_rank)
        # print("Sparse ", vol_feat['mean_feat'].shape, vol_feat['coord'].shape, 
        #     vol_feat['out_sh'], vol_feat['batch_size'], cfg.local_rank)

        self.register_buffer('mean_feat', vol_feat['mean_feat'])
        self.register_buffer('coord', vol_feat['coord'])
        self.register_buffer('out_sh', vol_feat['out_sh'])
        # self.register_buffer('batch_size', vol_feat['batch_size'])
        self.register_buffer('vox_min', vol_feat['vox_min'])

        # sp_img_feat = spconv.SparseConvTensor(
        #     vol_feat['mean_feat'], vol_feat['coord'], vol_feat['out_sh'], 
        #     vol_feat['batch_size'])

        return

    def cal_3d_conv(self):
        sp_img_feat = spconv.SparseConvTensor(
            self.mean_feat, self.coord, self.out_sh, 1)#self.batch_size)
        feature_volume = self.xyzc_net(sp_img_feat)
        # feature_volume = [sp_img_feat.dense()]

        return feature_volume

    def get_grid_coords(self, pts):
        #
        grid_coords = pts - self.vox_min
        grid_coords = grid_coords / torch.tensor(cfg.voxel_size).to(pts)

        grid_coords = 2 * grid_coords / self.out_sh - 1
        # grid_coords += (1.0/self.out_sh)
        # print("grid coords ", grid_coords[:10])
        return grid_coords.to(torch.float)

    def interpolate_features(self, grid_coords, feature_volume):
        features = []
        for volume in feature_volume:
            feature = F.grid_sample(volume,
                                    grid_coords,
                                    padding_mode='zeros',
                                    align_corners=True)
            features.append(feature)
        features = torch.cat(features, dim=1)
        features = features.view(features.size(0), -1, features.size(4))

        # feature_sum = torch.sum(features, dim=1).squeeze()
        # print("Features ", feature.shape, grid_coords.shape, feature_sum.shape,
        #     torch.nonzero(feature_sum).shape)
        return features

    # def calculate_density(self, wpts, feature_volume, sp_input):
    #     # interpolate features
    #     # ppts = self.pts_to_can_pts(wpts, sp_input)
    #     # grid_coords = self.get_grid_coords(ppts, sp_input)
    #     grid_coords = self.get_grid_coords(wpts)
    #     grid_coords = grid_coords[:, None, None]
    #     xyzc_features = self.interpolate_features(grid_coords, feature_volume)

    #     # calculate density
    #     net = self.actvn(self.fc_0(xyzc_features))
    #     net = self.actvn(self.fc_1(net))
    #     net = self.actvn(self.fc_2(net))

    #     alpha = self.alpha_fc(net)
    #     alpha = alpha.transpose(1, 2)

    #     return alpha

    def calculate_density_color(self, wpts, viewdir, feature_volume):
        # interpolate features
        # ppts = self.pts_to_can_pts(wpts, sp_input)
        # grid_coords = self.get_grid_coords(ppts, sp_input)
        grid_coords = self.get_grid_coords(wpts)
        grid_coords = grid_coords[:, None, None]
        # print("Interpolate shapes ", grid_coords.shape, feature_volume[0].shape)
        xyzc_features = self.interpolate_features(grid_coords, feature_volume)

        xyzc_sh = xyzc_features.shape

        xyzc_feat_sum = torch.sum(xyzc_features, dim=1).squeeze()
        xyzc_feat_idx = torch.nonzero(xyzc_feat_sum)

        # raw_output = torch.zeros(xyzc_sh[0], xyzc_sh[2], 4).to(xyzc_features)
        # xyzc_features = xyzc_features[:,:,xyzc_feat_idx[:, 0]]
        # viewdir = viewdir[:,xyzc_feat_idx[:, 0], :]

        # calculate density
        net = self.actvn(self.fc_0(xyzc_features))
        net = self.actvn(self.fc_1(net))
        net = self.actvn(self.fc_2(net))

        alpha = self.alpha_fc(net)

        # calculate color
        features = self.feature_fc(net)

        # latent = self.latent(sp_input['latent_index'])
        # latent = latent[..., None].expand(*latent.shape, net.size(2))
        # features = torch.cat((features, latent), dim=1)
        # features = self.latent_fc(features)

        viewdir = embedder.view_embedder(viewdir)
        viewdir = viewdir.transpose(1, 2).to(torch.float32)
        # light_pts = embedder.xyz_embedder(wpts)
        # light_pts = light_pts.transpose(1, 2).to(torch.float32)

        # print("Feature ", features.dtype, viewdir.dtype, light_pts.dtype)
        # print("Features ", features.shape, viewdir.shape)
        features = torch.cat((features, viewdir), dim=1)

        net = self.actvn(self.view_fc(features))
        rgb = self.rgb_fc(net)

        raw = torch.cat((rgb, alpha), dim=1)
        raw = raw.transpose(1, 2)
        # print("Features ", xyzc_features.shape, 
        #     torch.count_nonzero(xyzc_feat_sum.detach()),
        #     # torch.count_nonzero(alpha.detach()>0)
        #     torch.min(alpha.detach()), torch.max(alpha.detach()))

        # print("Features and output ", xyzc_features.shape, viewdir.shape,
        #     xyzc_feat_idx.shape, raw.shape, raw_output.shape)        

        # raw_output[:,xyzc_feat_idx[:,0],:] = raw
        return raw #raw_output


class SimSparseConvNet(nn.Module):
    def __init__(self):
        super(SimSparseConvNet, self).__init__()

        self.conv0 = single_spr_conv(2048, 1024, dim=3, indice_key='subm0')
        self.conv1 = single_spr_conv(1024, 512, dim=3, indice_key='subm1')
        self.conv2 = single_spr_conv(512, 256, dim=3, indice_key='subm2')

    def forward(self, x):
        net = self.conv0(x)
        net = self.conv1(net)
        net = self.conv2(net)
        net = net.dense()

        volumes = [net]

        return volumes

class SparseConvNet(nn.Module):
    def __init__(self):
        super(SparseConvNet, self).__init__()

        self.conv0 = double_conv(2048, 1024, 'subm0')
        self.down0 = stride_conv(1024, 512, 'down0')

        self.conv1 = double_conv(512, 256, 'subm1')
        self.down1 = stride_conv(256, 128, 'down1')

        self.conv2 = triple_conv(128, 128, 'subm2')
        self.down2 = stride_conv(128, 128, 'down2')

        self.conv3 = triple_conv(128, 128, 'subm3')
        self.down3 = stride_conv(128, 128, 'down3')

        self.conv4 = triple_conv(128, 128, 'subm4')

    def forward(self, x):
        net = self.conv0(x)
        net = self.down0(net)

        net = self.conv1(net)
        net1 = net.dense()
        net = self.down1(net)

        net = self.conv2(net)
        net2 = net.dense()
        net = self.down2(net)

        net = self.conv3(net)
        net3 = net.dense()
        net = self.down3(net)

        net = self.conv4(net)
        net4 = net.dense()

        volumes = [net1, net2, net3, net4]

        return volumes


def single_conv(in_channels, out_channels, dim=1, indice_key=None):
    return spconv.SparseSequential(
        spconv.SubMConv3d(in_channels,
                          out_channels,
                          dim,
                          bias=False,
                          indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01),
        nn.ReLU(),
    )

def single_spr_conv(in_channels, out_channels, dim=1, indice_key=None):
    return spconv.SparseSequential(
        spconv.SparseConv3d(in_channels,
                          out_channels,
                          dim,
                          bias=False,
                          indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01),
        nn.ReLU(),
    )


def double_conv(in_channels, out_channels, indice_key=None):
    return spconv.SparseSequential(
        spconv.SubMConv3d(in_channels,
                          out_channels,
                          3,
                          bias=False,
                          indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01),
        nn.ReLU(),
        spconv.SubMConv3d(out_channels,
                          out_channels,
                          3,
                          bias=False,
                          indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01),
        nn.ReLU(),
    )


def triple_conv(in_channels, out_channels, indice_key=None):
    return spconv.SparseSequential(
        spconv.SubMConv3d(in_channels,
                          out_channels,
                          3,
                          bias=False,
                          indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01),
        nn.ReLU(),
        spconv.SubMConv3d(out_channels,
                          out_channels,
                          3,
                          bias=False,
                          indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01),
        nn.ReLU(),
        spconv.SubMConv3d(out_channels,
                          out_channels,
                          3,
                          bias=False,
                          indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01),
        nn.ReLU(),
    )


def stride_conv(in_channels, out_channels, indice_key=None):
    return spconv.SparseSequential(
        spconv.SparseConv3d(in_channels,
                            out_channels,
                            3,
                            2,
                            padding=1,
                            bias=False,
                            indice_key=indice_key),
        nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01), nn.ReLU())
